defaults:
 - _self_
 - architecture: large
 - strategy: tresnet-clever
 - training: batches
 - dataset: ihdp
 - optimizer: sgd
    
seed: 1234
# dataset: ihdp  # ihdp, news, sim-B, sim-N, tcga-1, tcga-2, tcga-3
activation: ReLU  # most be a valid torch.nn activation layer

shift:
  type: percent  # percent,
  num: 10
  min: 0.0
  max: 0.5

body:
  hidden_dim: ???
  hidden_layers: ???
  independent_encoders: false

treatment:
  hidden_dim: ???
  hidden_layers: 0
  loss: classifier  # ps, hybrid, classifier, multips
  label_smoothing: 0.1
  freeze: false
  grid_size: 20  # only for discrete density estimators
  weight: 1.0
  norm: false
  norm_weight: 0.0

outcome:
  hidden_dim: ???
  hidden_layers: 0
  freeze: false
  backbone: vc  # vc, causalmlp, piecewise
  weight: 1.0
  training_noise: 0.1  # noise added to the predictor during training
                       # to prevent overfitting

tr:
  clever: true
  type: discrete  # discrete, spline, vcnet
  base_weight: 0.25
  freeze: false
  tmle: false  # in tmle, independent nets are learned (e.g., as in aipw),
               # then the fluctuation parameter is learned during finetuning
               # adjust the parameter training.finetune.after accordingly
  consistency: 0.0  # as a fraction of the tr.weight
  spline_knots:
    - 0.1
    - 0.2  # make sure they make sense related to the shift
  spline_degree: 2

estimator: tr # ipw, aipw, outcome, tr
estimator_ma_weight: 0.1  # in terms of epochs

training:
  epochs: 500
  dropout: 0.0
  num_workers: 0
  tr_opt_freq: 20
  finetune:
    after: 0.9  # num. epochs after which stop feature learning and dropout 1 = never
    mask_ratio: 0.0  # data masked before finetuning
    freeze_nuisance: false
    decrease_lr_after: 1.0 # num. epochs after which decrease learning rate 1 = never
  plot_every: 0.1  # in terms of epochs  # 0 = always
  progbar: true
  monitor: null  # choose a valid metric logged with lightning
  shuffle_batches: true
  grad_clip: 1.0  # value gradient clipping

loggers:
  csv: false
  tb: true

compile: false
family: gaussian  # gaussian, poisson, bernoulli:
force_mse: false  # force mse loss for the outcome model
                  # (useful for poisson and bernoulli outcomes)
                  # if false, the loss is chosen automatically
                  # based on the outcome family
dataset:
  _target_: ???  # must point to the class to instantaite the dataset
  noise_scale: 0.25 
  outcome_scale: 1.0

logdir: logs
subdir: ${now:%Y-%m-%d_%H-%M-%S}
choices:
  strategy: ${hydra.runtime.choices.strategy}
  architecture: ${hydra.runtime.choices.architecture}
  dataset: ${hydra.runtime.choices.dataset}

hydra:
  run:
    dir: ${logdir}/${choices.dataset}_${family}/${choices.strategy}_${outcome.backbone}_${choices.architecture}/${seed}/${subdir}
