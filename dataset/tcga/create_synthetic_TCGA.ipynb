{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "import torch \n",
    "\n",
    "import requests\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Download the TCGA data by running the cell below\n",
    "\n",
    "As specified here: https://github.com/ioanabica/SCIGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gdown\n",
    "\n",
    "url = 'https://drive.google.com/file/d/1P-smWytRNuQFjqR403IkJb17CXU6JOM7/view'\n",
    "output = 'tcga.p'\n",
    "gdown.download(url, output, quiet=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utility functions and classes for synthetic data creation\n",
    "\n",
    "Reference: https://arxiv.org/pdf/2002.12326.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "\n",
    "def softmax(x):\n",
    "    e_x = np.exp(x)\n",
    "    return e_x / e_x.sum(axis=0)\n",
    "\n",
    "\n",
    "def compute_beta(alpha, optimal_dosage):\n",
    "    if (optimal_dosage <= 0.001 or optimal_dosage >= 1.0):\n",
    "        beta = 1.0\n",
    "    else:\n",
    "        beta = (alpha - 1.0) / float(optimal_dosage) + (2.0 - alpha)\n",
    "\n",
    "    return beta\n",
    "\n",
    "\n",
    "def generate_patient(x, v, num_treatments, treatment_selection_bias, dosage_selection_bias,\n",
    "                     scaling_parameter, noise_std):\n",
    "    outcomes = []\n",
    "    dosages = []\n",
    "\n",
    "    for treatment in range(num_treatments):\n",
    "        if (treatment == 0):\n",
    "            b = 0.75 * np.dot(x, v[treatment][1]) / (np.dot(x, v[treatment][2]))\n",
    "\n",
    "            if (b >= 0.75):\n",
    "                optimal_dosage = b / 3.0\n",
    "            else:\n",
    "                optimal_dosage = 1.0\n",
    "\n",
    "            alpha = dosage_selection_bias\n",
    "            dosage = np.random.beta(alpha, compute_beta(alpha, optimal_dosage))\n",
    "\n",
    "            y = get_patient_outcome(x, v, treatment, dosage, scaling_parameter)\n",
    "\n",
    "        elif (treatment == 1):\n",
    "            optimal_dosage = np.dot(x, v[treatment][2]) / (2.0 * np.dot(x, v[treatment][1]))\n",
    "            alpha = dosage_selection_bias\n",
    "            dosage = np.random.beta(alpha, compute_beta(alpha, optimal_dosage))\n",
    "            if (optimal_dosage <= 0.001):\n",
    "                dosage = 1 - dosage\n",
    "\n",
    "            y = get_patient_outcome(x, v, treatment, dosage, scaling_parameter)\n",
    "\n",
    "        elif (treatment == 2):\n",
    "            optimal_dosage = np.dot(x, v[treatment][1]) / (2.0 * np.dot(x, v[treatment][2]))\n",
    "            alpha = dosage_selection_bias\n",
    "            dosage = np.random.beta(alpha, compute_beta(alpha, optimal_dosage))\n",
    "            if (optimal_dosage <= 0.001):\n",
    "                dosage = 1 - dosage\n",
    "\n",
    "            y = get_patient_outcome(x, v, treatment, dosage, scaling_parameter)\n",
    "\n",
    "        outcomes.append(y)\n",
    "        dosages.append(dosage)\n",
    "\n",
    "    treatment_coeff = [treatment_selection_bias * (outcomes[i] / np.max(outcomes)) for i in range(num_treatments)]\n",
    "    treatment = np.random.choice(num_treatments, p=softmax(treatment_coeff))\n",
    "\n",
    "    return treatment, dosages[treatment], outcomes[treatment] + np.random.normal(0, noise_std)\n",
    "\n",
    "\n",
    "def get_patient_outcome(x, v, treatment, dosage, scaling_parameter=10):\n",
    "    if (treatment == 0):\n",
    "        y = float(scaling_parameter) * (np.dot(x, v[treatment][0]) + 12.0 * dosage * (dosage - 0.75 * (\n",
    "                np.dot(x, v[treatment][1]) / np.dot(x, v[treatment][2]))) ** 2)\n",
    "    elif (treatment == 1):\n",
    "        y = float(scaling_parameter) * (np.dot(x, v[treatment][0]) + np.sin(\n",
    "            np.pi * (np.dot(x, v[treatment][1]) / np.dot(x, v[treatment][2])) * dosage))\n",
    "    elif (treatment == 2):\n",
    "        y = float(scaling_parameter) * (np.dot(x, v[treatment][0]) + 12.0 * (np.dot(x, v[treatment][\n",
    "            1]) * dosage - np.dot(x, v[treatment][2]) * dosage ** 2))\n",
    "\n",
    "    return y\n",
    "\n",
    "\n",
    "def get_dataset_splits(dataset):\n",
    "    dataset_keys = ['x', 't', 'd', 'y', 'y_normalized']\n",
    "\n",
    "    train_index = dataset['metadata']['train_index']\n",
    "    val_index = dataset['metadata']['val_index']\n",
    "    test_index = dataset['metadata']['test_index']\n",
    "\n",
    "    dataset_train = dict()\n",
    "    dataset_val = dict()\n",
    "    dataset_test = dict()\n",
    "    for key in dataset_keys:\n",
    "        dataset_train[key] = dataset[key][train_index]\n",
    "        dataset_val[key] = dataset[key][val_index]\n",
    "        dataset_test[key] = dataset[key][test_index]\n",
    "\n",
    "    dataset_train['metadata'] = dataset['metadata']\n",
    "    dataset_val['metadata'] = dataset['metadata']\n",
    "    dataset_test['metadata'] = dataset['metadata']\n",
    "\n",
    "    return dataset_train, dataset_val, dataset_test\n",
    "\n",
    "\n",
    "def get_split_indices(num_patients, patients, treatments, validation_fraction, test_fraction):\n",
    "    num_validation_patients = int(np.floor(num_patients * validation_fraction))\n",
    "    num_test_patients = int(np.floor(num_patients * test_fraction))\n",
    "\n",
    "    test_sss = StratifiedShuffleSplit(n_splits=1, test_size=num_test_patients, random_state=0)\n",
    "    rest_indices, test_indices = next(test_sss.split(patients, treatments))\n",
    "\n",
    "    val_sss = StratifiedShuffleSplit(n_splits=1, test_size=num_validation_patients, random_state=0)\n",
    "    train_indices, val_indices = next(val_sss.split(patients[rest_indices], treatments[rest_indices]))\n",
    "\n",
    "    return train_indices, val_indices, test_indices\n",
    "\n",
    "\n",
    "class TCGA_Data():\n",
    "    def __init__(self, args):\n",
    "        np.random.seed(3)\n",
    "\n",
    "        self.num_treatments = args['num_treatments']\n",
    "        self.treatment_selection_bias = args['treatment_selection_bias']\n",
    "        self.dosage_selection_bias = args['dosage_selection_bias']\n",
    "\n",
    "        self.validation_fraction = args['validation_fraction']\n",
    "        self.test_fraction = args['test_fraction']\n",
    "    \n",
    "        self.tcga_data = pickle.load(open(args['data_path'], 'rb'))\n",
    "        self.patients = self.normalize_data(self.tcga_data['rnaseq'])\n",
    "\n",
    "        self.scaling_parameteter = 10\n",
    "        self.noise_std = 0.2\n",
    "\n",
    "        self.num_weights = 3\n",
    "        self.v = np.zeros(shape=(self.num_treatments, self.num_weights, self.patients.shape[1]))\n",
    "\n",
    "        for i in range(self.num_treatments):\n",
    "            for j in range(self.num_weights):\n",
    "                self.v[i][j] = np.random.uniform(0, 10, size=(self.patients.shape[1]))\n",
    "                self.v[i][j] = self.v[i][j] / np.linalg.norm(self.v[i][j])\n",
    "\n",
    "        self.dataset = self.generate_dataset(self.patients, self.num_treatments)\n",
    "\n",
    "    def normalize_data(self, patient_features):\n",
    "        x = (patient_features - np.min(patient_features, axis=0)) / (\n",
    "                np.max(patient_features, axis=0) - np.min(patient_features, axis=0))\n",
    "\n",
    "        for i in range(x.shape[0]):\n",
    "            x[i] = x[i] / np.linalg.norm(x[i])\n",
    "\n",
    "        return x\n",
    "\n",
    "    def generate_dataset(self, patient_features, num_treatments):\n",
    "        tcga_dataset = dict()\n",
    "        tcga_dataset['x'] = []\n",
    "        tcga_dataset['y'] = []\n",
    "        tcga_dataset['t'] = []\n",
    "        tcga_dataset['d'] = []\n",
    "        tcga_dataset['metadata'] = dict()\n",
    "        tcga_dataset['metadata']['v'] = self.v\n",
    "        tcga_dataset['metadata']['treatment_selection_bias'] = self.treatment_selection_bias\n",
    "        tcga_dataset['metadata']['dosage_selection_bias'] = self.dosage_selection_bias\n",
    "        tcga_dataset['metadata']['noise_std'] = self.noise_std\n",
    "        tcga_dataset['metadata']['scaling_parameter'] = self.scaling_parameteter\n",
    "\n",
    "        for patient in patient_features:\n",
    "            t, dosage, y = generate_patient(x=patient, v=self.v, num_treatments=num_treatments,\n",
    "                                            treatment_selection_bias=self.treatment_selection_bias,\n",
    "                                            dosage_selection_bias=self.dosage_selection_bias,\n",
    "                                            scaling_parameter=self.scaling_parameteter,\n",
    "                                            noise_std=self.noise_std)\n",
    "            tcga_dataset['x'].append(patient)\n",
    "            tcga_dataset['t'].append(t)\n",
    "            tcga_dataset['d'].append(dosage)\n",
    "            tcga_dataset['y'].append(y)\n",
    "\n",
    "        for key in ['x', 't', 'd', 'y']:\n",
    "            tcga_dataset[key] = np.array(tcga_dataset[key])\n",
    "\n",
    "        tcga_dataset['metadata']['y_min'] = np.min(tcga_dataset['y'])\n",
    "        tcga_dataset['metadata']['y_max'] = np.max(tcga_dataset['y'])\n",
    "\n",
    "        tcga_dataset['y_normalized'] = (tcga_dataset['y'] - np.min(tcga_dataset['y'])) / (\n",
    "                np.max(tcga_dataset['y']) - np.min(tcga_dataset['y']))\n",
    "\n",
    "        train_indices, validation_indices, test_indices = get_split_indices(num_patients=tcga_dataset['x'].shape[0],\n",
    "                                                                            patients=tcga_dataset['x'],\n",
    "                                                                            treatments=tcga_dataset['t'],\n",
    "                                                                            validation_fraction=self.validation_fraction,\n",
    "                                                                            test_fraction=self.test_fraction)\n",
    "\n",
    "        tcga_dataset['metadata']['train_index'] = train_indices\n",
    "        tcga_dataset['metadata']['val_index'] = validation_indices\n",
    "        tcga_dataset['metadata']['test_index'] = test_indices\n",
    "\n",
    "        return tcga_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://drive.google.com/file/d/1P-smWytRNuQFjqR403IkJb17CXU6JOM7/view'\n",
    "r = requests.get(url, allow_redirects=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_params = dict()\n",
    "dataset_params['num_treatments'] = 1\n",
    "dataset_params['treatment_selection_bias'] = 2.0\n",
    "dataset_params['dosage_selection_bias'] = 2.0\n",
    "dataset_params['save_dataset'] = False\n",
    "dataset_params['validation_fraction'] = 0.1\n",
    "dataset_params['test_fraction'] = 0.2\n",
    "dataset_params['data_path'] = \"tcga.p\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run dataset creation process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_class = TCGA_Data(dataset_params)\n",
    "dataset = data_class.dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Export useful data variables "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "to_export = dict()\n",
    "\n",
    "to_export[\"x\"] = dataset[\"x\"]\n",
    "to_export[\"y\"] = dataset[\"y_normalized\"]\n",
    "to_export[\"t\"] = dataset[\"d\"]\n",
    "to_export[\"train_idx\"] = np.array(list(dataset[\"metadata\"][\"train_index\"]) + list(dataset[\"metadata\"][\"val_index\"]))\n",
    "to_export[\"test_idx\"] = dataset[\"metadata\"][\"test_index\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dictionary saved successfully to file\n"
     ]
    }
   ],
   "source": [
    "with open('tcga_semi_synthetic.pkl', 'wb') as fp:\n",
    "    \n",
    "    pickle.dump(to_export, fp)\n",
    "    print('dictionary saved successfully to file')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Note\n",
    "\n",
    "The semi-synthetic TCGA data has been saved `tcga_semi_synthetic.pkl` in the same folder as this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5 (default, Sep  4 2020, 02:22:02) \n[Clang 10.0.0 ]"
  },
  "vscode": {
   "interpreter": {
    "hash": "36f1192590badfeb713a4c76ab59fe4d3691d3166b8a5b03e86cd38b46689629"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
